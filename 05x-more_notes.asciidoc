-- EXERCISE: find the Bill James' "Gray Ink" score for each player: four points
--   per season they were in the top ten for HR, RBI or AVG; three points for R,
--   H, SLG; two points for 2B, BB or SB, and one point for each season in the
--   top ten for G, AB or 3B.  (See
--   http://baseball-reference.com/about/leader_glossary.shtml[Baseball
--   Reference] for a bit more of a description and the pitching equivalent).
--   uses GROUP-TOP-FOREACH (isEmpty ? 1 : 0)-GROUP-FOREACH (summing and
--   weighting the composite pieces of ink.



==== Flatten a Tuple of `field name, field value` pairs

If you want to simultaneously apply a dataflow to a large number of columns,
skip ahead to the statistics chapter, where we'll show how to use a UDF to transpose columns Into `field name, field value` pairs


=== (notes for later) 


* http://www.stat.berkeley.edu/users/spector/sql.pdf
  * SELECT * FROM kids GROUP BY id HAVING COUNT(*) = 10;
  * SELECT * FROM kids WHERE id IN (SELECT id FROM kids GROUP BY id HAVING COUNT(*) = 10);
  * SELECT * FROM kids INNER JOIN (SELECT id FROM kids GROUP BY id HAVING COUNT(*) = 10) AS t USING(id);
  * SELECT * FROM kids WHERE weight = (SELECT MAX(weight) FROM kids);
  * SELECT k.id,k.sex,k.race,k.age,k.weight,k.height FROM kids AS k, (SELECT sex,race,max(weight) AS weight from kids) AS m WHERE k.sex=m.sex AND k.race=m.race AND k.weight=m.weight; SELECT a.title,r.name FROM album AS a, artist AS r WHERE a.aid = r.aid;
  * To improve our previous example, we need to combine the track information with album and artist information. Suppose we want to find the 10 longest albums in the collection:
SELECT a.title,r.name,SUM(time) AS duration FROM track AS t, album as a, artist as r WHERE t.alid = a.alid AND a.aid = r.aid GROUP BY t.alid ORDER BY duration DESC LIMIT 1,10;
* http://justpain.com/eBooks/Databases/MySQL/MySQL%20Cookbook.pdf
* Art of SQL
  * Hierarchy: WITH parent (ckey) AS (SELECT DISTINCT pkey FROM   hierarchy WHERE  pkey = 'AAA' UNION ALL SELECT C.ckey FROM   hierarchy C ,parentP WHERE  P.ckey = C.pkey ) SELECT ckey FROM   parent; Figure 858, 
  * True if NONE Match Find all rows in TABLE1 where there are no rows in TABLE2 that have a T2C value equal to the current T1A value in the TABLE1 table: SELECT * FROM   table1 t1 WHERE  0 = (SELECT COUNT(*) FROM   table2 t2 WHERE  t1.t1a = t2.t2c); TABLE1 TABLE2 +-------+ +-----------+ |T1A|T1B| |T2A|T2B|T2C| |---|---| |---|---|---| |A|AA| |A|A|A| |B|BB| |B |A |-| |C |CC | +-----------+ SELECT * FROM   table1 t1 WHERE  NOT EXISTS (SELECT * FROM   table2 WHERE  t1.t1a SELECT * FROM   table1 WHERE  t1a NOT IN +-------+ "-" = null ANSWER ======= T1A T1B --- --- B   BB C   CC (SELECT t2c FROM   table2 WHERE  t2c IS NOT NULL); Figure 716, Sub-queries, true if none match t2 = t2.t2c);
  * Figure 720, Sub-queries, true if ten match The first two queries above use a correlated sub-query. The third is uncorrelated: True if TEN Match Find all rows in TABLE1 where there are exactly ten rows in TABLE2 that have a T2B value equal to the current T1A value in the TABLE1 table: SELECT * FROM   table1 WHERE  10 = (SELECT FROM WHERE SELECT * FROM   table1 WHERE  EXISTS (SELECT FROM WHERE GROUP BY t2b HAVING   COUNT(*) = 10); SELECT * FROM   table1 WHERE  t1a IN (SELECT   t2b FROM     table2 GROUP BY t2b HAVING   COUNT(*) = 10); 
* Using geo spatial to do graph queries
  - From preso on titanDB: 33. Use case 2 ● In human proteome, find all chemical groups A and B separated by less then x Å – Database Structure: ● Suppose all the proteins are connected to a “Type node” ● Each protein is linked to it's domains, each domain is linked to it's amino acids, each amino-acid linked to it's chemical groups and ultimately atoms ● Chemical groups have assigned distance between them and groups they are close to – Algorithm ● Select a protein of interest ● Get all of it's chemical groups: 1000(a.a)*3(ch.gr/a.a) ● Filter all of the Relations longer than k: 1000*3*100(possible contacts per ch.gr) ● Recover the proteins: 1000*3*100*2 ● With 1M traversals per second => 0.6 sec. to execute the query – If TitanDB with ElasticSearch and geo-queries (all within circle of radius x), higher speeds possible

* A hint: for some operations on all pairs (a,b) you can filter by (a <= b)...

==== Generating good random numbers

* http://blog.codinghorror.com/shuffling/
* http://opencoursesfree.org/archived_courses/cs.berkeley.edu/~mhoemmen/cs194/Tutorials/prng.pdf
    * "numbers with statistical properties of randomness. Note that I didn’t write “random numbers,” but rather, “numbers with statistical properties of randomness.”"
* Make sure you have enough bits
* Even 52 cards has 52! =~ 255 bits of permutation... can't possibly get every permutation for a table of even modest size
* Make sure you look out for ties and shuffle them as well
* Do you have to be think-y about the partitioner?
* Download about (8 years *365 days * 1 mebibyte) of randoms from random.org. This is however only 90 million 256-bit (32-byte) numbers, or 350 million 64-bit (8-byte) numbers.
* Don't just (rand mod 25) for a 1-in-25 random sample -- you'll be biased because it's not an exact number of bits. Instead reject if > 25 and try again.
* Watch out for non-reentrant rand() -- mutex or something (do we need to worry about this in hadoop?)
* http://blog.cloudera.com/blog/2013/02/how-to-resample-from-a-large-data-set-in-parallel-with-r-on-hadoop/
    * Sampling-with-replacement is the most popular method for sampling from the initial data set to produce a collection of samples for model fitting. This method is equivalent to sampling from a multinomial distribution where the probability of selecting any individual input data point is uniform over the entire data set. Unfortunately, it is not possible to sample from a multinomial distribution across a cluster without using some kind of communication between the nodes (i.e., sampling from a multinomial is not embarrassingly parallel). But do not despair: we can approximate a multinomial distribution by sampling from an identical Poisson distribution on each input data point independently, lending itself to an embarrassingly parallel implementation.

Here's a clip from the PokerStars website (they did their homework):

* A deck of 52 cards can be shuffled in 52! ways. 52! is about 2^225 (to be precise, 80,658,175,170,943,878,571,660,636,856,404,000,000,000,000,000 ways). We use 249 random bits from both entropy sources (user input and thermal noise) to achieve an even and unpredictable statistical distribution.
* Furthermore, we apply conservative rules to enforce the required degree of randomness; for instance, if user input does not generate required amount of entropy, we do not start the next hand until we obtain the required amount of entropy from Intel RNG.
* We use the SHA-1 cryptographic hash algorithm to mix the entropy gathered from both sources to provide an extra level of security
* We also maintain a SHA-1-based pseudo-random generator to provide even more security and protection from user data attacks
* To convert random bit stream to random numbers within a required range without bias, we use a simple and reliable algorithm. For example, if we need a random number in the range 0-25:
      o we take 5 random bits and convert them to a random number 0-31
      o if this number is greater than 25 we just discard all 5 bits and repeat the process
* This method is not affected by biases related to modulus operation for generation of random numbers that are not 2n, n = 1,2,..
* To perform an actual shuffle, we use another simple and reliable algorithm:
      o first we draw a random card from the original deck (1 of 52) and place it in a new deck - now original deck contains 51 cards and the new deck contains 1 card
      o then we draw another random card from the original deck (1 of 51) and place it on top of the new deck - now original deck contains 50 cards and the new deck contains 2 cards
      o we repeat the process until all cards have moved from the original deck to the new deck
* This algorithm does not suffer from "Bad Distribution Of Shuffles" described in [2]

[2] "How We Learned to Cheat at Online Poker: A Study in Software Security" - http://itmanagement.earthweb.com/entdev/article.php/616221
[3] "The Intel Random Number Generator" - http://www.cryptography.com/resources/whitepapers/IntelRNG.pdf"

==== Tuning

Use the fewest reduce steps reasonable,
And reduce on the least data reasonable.
But it rarely makes sense to use an extra reduce to ship less data 

===== From programming pig:

Table 8-1. When Pig pushes filters
Preceding operator	Filter will be pushed before?	Comments
cogroup	Sometimes	The filter will be pushed if it applies to only one input of the cogroup and does not contain a UDF.
cross	Sometimes	The filter will be pushed if it applies to only one input of the cross.
distinct	Yes	 
filter	No	Will seek to merge them with and to avoid passing data through a second operator. This is done only after all filter pushing is complete.
foreach	Sometimes	The filter will be pushed if it references only fields that exist before and after the foreach, and foreach does not transform those fields.
group	Sometimes	The filter will be pushed if it does not contain a UDF.
join	Sometimes	The filter will be pushed if it applies to only one input of the join, and if the join is not outer for that input.
load	No	 
mapreduce	No	mapreduce is opaque to Pig, so it cannot know whether pushing will be safe.
sort	Yes	 
split	No	 
store	No	 
stream	No	stream is opaque to Pig, so it cannot know whether pushing will be safe.
union	Yes	 
Also, consider adding filters that are implicit in your script. For example, all of the records with null values in the key will be thrown out by an inner join. If you know that more than a few hundred of your records have null key values, put a filter input by key is not null before the join. This will enhance the performance of your join.



SELECT COUNT(*), SUM(IF(stint = 1, 1, 0)), SUM(IF(stint =0, 1, 0)), SUM(IF(stint = 2, 1, 0)) FROM batting WHERE stint <= 99
;

SELECT tot_bl_stints, tot_bl_seasons, tot_bw_stints, COUNT(*), COUNT(*)/tot_bl_seasons FROM
  (SELECT COUNT(*) AS tot_bl_seasons FROM bat_season) t4,
  (SELECT COUNT(*) AS tot_bw_stints FROM bat_war) t2,
  (SELECT COUNT(*) AS tot_bl_stints FROM batting) t3,
  (SELECT COUNT(*) AS n_stints FROM batting GROUP BY playerID, yearID HAVING n_stints > 1) stintful
  ;

SELECT COUNT(*), stints FROM 
(SELECT GROUP_CONCAT(stint) AS stints FROM batting GROUP BY playerID, yearID) t1
GROUP BY stints;

SELECT * FROM bat_war WHERE playerID LIKE "%purceda01%";
SELECT GROUP_CONCAT(stint) AS stints, batting.*  FROM batting GROUP BY playerID, yearID HAVING stints = "2" OR stints = "3";


SELECT bw.*
FROM bat_war bw
LEFT JOIN batting bl ON bw.playerID = bl.playerID AND bw.yearID = bl.yearID AND bw.stint = bl.stint
WHERE bl.playerID IS NULL AND bw.yearID != 2013
