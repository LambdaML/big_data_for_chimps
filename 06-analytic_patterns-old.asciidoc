
=== How a group works

------
team_n_parks = FOREACH (GROUP park_teams BY (team_id,year_id)) GENERATE
  group.team_id, COUNT_STAR(park_teams) AS n_parks;
vagabonds = FILTER team_n_parks BY n_parks >= 3;

DUMP vagabonds;
(CL4,7)
(CLE,5)
(WS3,4)
(CLE,3)
(DET,3)
...
------

------
mapper(array_fields_of: ParkTeamYear) do |park_id, team_id, year_id, beg_date, end_date, n_games|
 yield [team_id, year_id]
end

# In effect, what is happening in Java:
reducer do |(team_id, year_id), stream|
  n_parks = 0
  stream.each do |*_|
    n_parks += 1
  end
  yield [team_id, year_id, n_parks] if n_parks > 1
end
------

(In actual practice, the ruby version would just call `n_parks = stream.size` rather than iterating)


TODO in part on groups note As Jon Covent says, "Bags are what makes Pig Awesome". SQL doesn't have them, and they bring extraordinary power. They can be of arbitrarily large size, present an ad-hoc object representation, and within limits can themselves be limited, transformed, ordered, threaded, and joined.
They can't be indexed into, and unless you explicitly say so are not ordered.

TODO add diagram showing inner bag like the ThinkBig demo (and reference it)

TODO: a JOIN is used for: direct foreign key join; matching records on a criterion, possibly sparsely; set intersection.

For the examples in this chapter and often throughout the book, we will use the Retrosheet.org compendium of baseball data. We will briefly describe tables as we use them, but for a full explanation of its structure see the "Overview of Datasets" appendix (TODO:  REF).

The core operation you will use to put records from one table into context with data from another table is the JOIN. A common application of the JOIN is to reunite data that has been normalized -- that is to say, where the database tables are organized to eliminate any redundancy. For example, each Retrosheet game log lists the ballpark in which it was played but, of course, it does not repeat the full information about that park within every record. Later in the book, (TODO:  REF) we will want to label each game with its geo-coordinates so we can augment each with official weather data measurements.

To join the game_logs table with the parks table, extracting the game time and park geocoordinates, run the following Pig command:

------
gls_with_parks_j = JOIN
   parks     BY (park_id),
   game_logs BY (park_id);
explain gls_with_parks_j;
gls_with_parks = FOREACH gls_with_parks_j GENERATE
 (game_id, gamelogs.park_id, game_time, park_lng, statium_lat);
explain gls_with_parks;
(TODO output of explain command)
------

The output schema of the new `gls_with_parks` table has all the fields from the `parks` table first (because it's first in the join statement), stapled to all the fields from the `game_logs` table. We only want some of the fields, so immediately following the JOIN is a FOREACH to extract what we're interested in. Note there are now two 'park_id' columns, one from each dataset, so in the subsequent FOREACH, we need to dereference the column name with the table from which it came. (TODO: check that Pig does push the projection of fields up above the JOIN). If you run the script, 'examples/geo/baseball_weather/geolocate_games.pig' you will see that its output has example as many records as there are 'game_logs' because there is exactly one entry in the 'parks' table for each park.

In the general case, though, a JOIN can be many to many. Suppose we wanted to build a table listing all the home ballparks for every player over their career. The 'player_seasons' table has a row for each year and team over their career. If a player changed teams mid year, there will be two rows for that player. The 'park_years' table, meanwhile, has rows by season for every team and year it was used as a home stadium. Some ballparks have served as home for multiple teams within a season and in other cases (construction or special circumstances), teams have had multiple home ballparks within a season.

The Pig script (TODO: write script) includes the following JOIN:

------
JOIN
player_park_years=JOIN
 parks(year,team_ID),
 players(year,team_ID);
explain_player_park_year;
------

First notice that the JOIN expression has multiple columns in this case separated by commas; you can actually enter complex expressions here -- almost all (but not all) the things you do within a FOREACH. If you examine the output file (TODO: name of output file), you will notice it has appreciably more lines than the input 'player' file. For example (TODO: find an example of a player with multiple teams having multiple parks), in year x player x played for the x and the y and y played in stadiums p and q. The one line in the 'players' table has turned into three lines in the 'players_parks_years' table.

The examples we have given so far are joining on hard IDs within closely-related datasets, so every row was guaranteed to have a match. It is frequently the case, however, you will join tables having records in one or both tables that will fail to find a match. The 'parks_info' datasets from Retrosheet only lists the city name of each ballpark, not its location. In this case we found a separate human-curated list of ballpark geolocations, but geolocating records -- that is, using a human-readable location name such as "Austin, Texas" to find its nominal geocoordinates (-97.7,30.2) -- is a common task; it is also far more difficult than it has any right to be, but a useful first step is match the location names directly against a gazette of populated place names such as the open source Geonames dataset.

Run the script (TODO: name of script) that includes the following JOIN:

------
park_places = JOIN
 parks BY (location) LEFT OUTER,
 places BY (concatenate(city, ", ", state);
DESCRIBE park_places;
------

In this example, there will be some parks that have no direct match to location names and, of course, there will be many, many places that do not match a park. The first two JOINs we did were "inner" JOINs -- the output contains only rows that found a match. In this case, we want to keep all the parks, even if no places matched but we do not want to keep any places that lack a park. Since all rows from the left (first most dataset) will be retained, this is called a "left outer" JOIN. If, instead, we were trying to annotate all places with such parks as could be matched -- producing exactly one output row per place -- we would use a "right outer" JOIN instead. If we wanted to do the latter but (somewhat inefficiently) flag parks that failed to find a match, you would use a "full outer" JOIN. (Full JOINs are pretty rare.)

TODO: discuss use of left join for set intersection.

In a Pig JOIN it is important to order the tables by size -- putting the smallest table first and the largest table last. (You'll learn why in the "Map/Reduce Patterns" (TODO:  REF) chapter.) So while a right join is not terribly common in traditional SQL, it's quite valuable in Pig. If you look back at the previous examples, you will see we took care to always put the smaller table first. For small tables or tables of similar size, it is not a big deal -- but in some cases, it can have a huge impact, so get in the habit of always following this best practice.

------
NOTE
A Pig join is outwardly similar to the join portion of a SQL SELECT statement, but notice that  although you can place simple expressions in the join expression, you can make no further manipulations to the data whatsoever in that statement. Pig's design philosophy is that each statement corresponds to a specific data transformation, making it very easy to reason about how the script will run; this makes the typical Pig script more long-winded than corresponding SQL statements but clearer for both human and robot to understand.
------

==== Reassemble a Vertically Partitioned Table

Another reason to split data across tables is 'vertical partitioning': storing fields that are very large or seldom used in context within different tables. That's the case with the Wikipedia article tables -- the geolocation information is only relevant for geodata analysis; the article text is both large and not always relevant.



Every stadium a player has played in. (We're going to cheat on the detail of
multiple stints and credit every player with all stadiums visited by the team
of his first stint in a season

------
  -- there are only a few many-to-many cases, so the 89583 seasons in batting
  -- table expands to only 91904 player-park-years. But it's a cross product, so
  -- beware.
SELECT COUNT(*) FROM batting bat WHERE bat.stint = 1;
SELECT bat.player_id, bat.team_id, bat.year_id, pty.park_id
  FROM       batting bat
  INNER JOIN park_team_years pty
    ON bat.year_id = pty.year_id AND bat.team_id = pty.team_id
  WHERE bat.stint = 1
  ORDER BY player_id
  ;
------

What if you only want the distinct player-team-years?
You might naively do a join and then a group by,
or a join and then distinct. Don't do that.

------
  -- DON'T DO THE (pig equivalent) OF THIS to find the distinct teams, years and parks;
  -- it's an extra reduce.
SELECT bat.player_id, bat.nameCommon,
    GROUP_CONCAT(DISTINCT pty.park_id) AS park_ids, COUNT(DISTINCT pty.park_id) AS n_parks,
    GROUP_CONCAT(DISTINCT bat.team_id) AS team_ids,
    MIN(bat.year_id) AS begYear, MAX(bat.year_id) AS endYear
  FROM       bat_war bat
  INNER JOIN park_team_years pty
    ON bat.year_id = pty.year_id AND bat.team_id = pty.team_id
  WHERE bat.stint = 1 AND player_id IS NOT NULL
  GROUP BY player_id
  HAVING begYear > 1900
  ORDER BY n_parks DESC, player_id ASC
  ;
  
  Join bat_yr on (team_id, year_id), pty by (team_id, year_id);
  FOREACH @ GENERATE bat_years::player_id, park_id;
  Group by player_id
  Distinct parks
  
  Cogroup baty by (team_id, year_id), pty by (team_id, year_id);
   distinct park_id, 
------

So now we disclose the most important thing that SQL experts need to break
their brains of:

In SQL, the JOIN is supreme.
In Pig, the GROUP is supreme

A JOIN is, for the most part, just sugar around a COGROUP-and-FLATTEN.
Very often you'll find the simplest path is through COGROUP not JOIN.

In this case, if you start by thinking of the group, you'll see you can eliminate a whole reduce.

(show pig, including a DISTINCT in the fancy-style FOREACH)

==== Join Practicalities

The output of the Join job has one line for each discrete combination of A and B. As you will notice in our Wukong version of the Join, the job receives all the A records for a given key in order, strictly followed by all the B records for that key in order. We have to accumulate all the A records in memory so we know what rows to emit for each B record. All the A records have to be held in memory at the same time, while all the B records simply flutter by; this means that if you have two datasets of wildly different sizes or distribution, it is worth ensuring the Reducer receives the smaller group first. In Wukong, you do this by giving it an earlier-occurring field group label; in Pig, always put the table with the largest number of records per key last in the statement.

==== Direct Join: Extend Records with Uniquely Matching Records from Another Table

* Direct Join:
  - Direct Join: Extend Records with Uniquely Matching Records from Another Table
  - Direct join on foreign key -- ages for each player season
  - join		Combining Related Records by Foreign Key (The solution is an example of a join, or more accurately an equi-join, which is a type of inner join. A join is an operation that combines rows from two tables into one. An equi-join is one in which the join condition is based on an equality condition (e.g., where one department number equals another). An inner join is the original type of join; each row returned contains data from each table.)


Using a join to extend the records in one table with the fields from one matching record in another is a very common pattern. Datasets are commonly stored as tables in 'normalized' form -- that is, having tables structured to minimize redundancy and dependency.

(Replace with the 'people' table)

The global hourly weather dataset has one table giving the metadata for every weather station: identifiers, geocoordinates, elevation, country and so on. The giant tables listing the hourly observations from each weather station are normalized to not repeat the station metadata on each line, only the weather station id. However, later in the book (REF) we'll do geographic analysis of the weather data -- and one of the first tasks will be to denormalize the geocoordinates of each weather station with its observations, letting us group nearby observations.

hang weight, height and BMI off of their OPS (overall hitting); ISO ("isolated power");
and number of stolen bases per time on base (loosely tied to speed)

------
SELECT bat.player_id, peep.nameCommon, begYear,
    peep.weight, peep.height,
    703*peep.weight/(peep.height*peep.height) AS BMI, -- measure of body type
    PA, OPS, ISO
  FROM bat_career bat
  JOIN people peep ON bat.player_id = peep.player_id
  WHERE PA > 500 AND begYear > 1910
  ORDER BY BMI DESC
  ;
------
(add note) Joins on null values are dropped even when both are null. Filter nulls. (I can't come up with a good example of this)
(add note) in contrast, all elements with null in a group _will_ be grouped as null. This can be dangerous when large number of nulls: all go to same reducer


=== SQL-to-Pig-to-Hive Cheatsheet

* SELECT..WHERE
* SELECT...LIMit
* GROUP BY...HAVING
* SELECT WHERE... ORDER BY
* SELECT WHERE... SORT BY (just use reducer sort) ~~ (does reducer in Pig guarantee this?)
* SELECT … DISTRIBUTE BY … SORT BY ...
* SELECT ... CLUSTER BY (equiv of distribute by X sort by X)
* Indexing tips
* CASE...when...then
* Block Sampling / Input pruning
* SELECT country_name, indicator_name, `2011` AS trade_2011 FROM wdi WHERE (indicator_name = 'Trade (% of GDP)' OR indicator_name = 'Broad money (% of GDP)') AND `2011` IS NOT NULL CLUSTER BY indicator_name;

SELECT columns or computations FROM table WHERE condition GROUP BY columns HAVING condition ORDER BY column  [ASC | DESC] LIMIT offset,count;

==== Ready Reckoner: How fast should your Pig fly? --> not sure what this is

TODO: move to the first tuning chapter.

The idea is to have you run through a set of pig scripts with datasets of defined size, measuring the throughput of the core operations. The result is a ready reckoner that lets you estimate how long your job _should_ take (and how many map-reduce stages it will use).


The fundamental Map/Reduce operation is to group a set of records and operate on that group. In fact, it’s a one-liner in Pig:

We can use `GROUP` to assemble an inline list of the stadiums each team played for by year:

------
teams_w_parks = FOREACH (GROUP team_parks BY team_id) GENERATE
    group as team_id, team_park_years.(year_id, park_id);

  -- (ALT,{(ALT01,ALT,1884,1884-04-30,1884-05-31,18)})
  -- (ANA,{(ANA01,ANA,2001,2001-04-10,2001-10-07,81),(ANA01,ANA,2010,2010-04-05,2010-09-29,81),...})
------


The result is always a tuple whose first field is named “group” -- holding the individual group keys in order. The next field has a bag of each the full input record with all its keys, even the group key.

Here’s a Wukong script that illustrates what is going on:

------
(TODO: Wukong script)
------

* Set operations summary
  - group2	setops	Determining Whether Two Tables Have the Same Data (is symmetric difference empty)  -
  - group2	setops	Retrieving Values from One Table That Do Not Exist in Another (set difference; players in batting but not pitching -- or in one but not other (symmetric difference)
  - group2	setops	Group Elements From Multiple Tables On A Common Attribute (COGROUP)
  - group2	setops	GROUP/COGROUP To Restructure Tables
  - group2	setops	Partition a Set into Subsets: SPLIT, but keep in mind that the SPLIT operation doesn't short-circuit.
  - group2	setops	Union of Sets UNION-then-DISTINCT, or COGROUP (note that it doesn't dedupe, doesn't order, and doesn't check for same schema. career stats tables; do it with cogroup, not union-distinct)
  - group2	setops	Prepare a Distinct Set from a Collection of Records: DISTINCT
  - group2	setops	Difference (in a but not in b): cogroup keep only empty (non-allstars)
  - group2	setops	Symmetric difference: in A or B but not in A intersect B -- do this with aggregation: count 0 or 1 and only keep 1
  - group2	setops	Equality (use symmetric difference): result should be empty
  - group2	setops	http://datafu.incubator.apache.org/docs/datafu/guide/set-operations.html and http://www.cs.tufts.edu/comp/150CPA/notes/Advanced_Pig.pdf

